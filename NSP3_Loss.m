% Loss values copied from TensorFlow output
clear all, close all, clc
Train_Loss_Sym4_4_CNN = [1758.4043 
1073.0460 
794.5577 
611.4312 
514.8794 
485.3777 
477.3330  
469.9248
468.6506 
462.3504 
459.0970 
454.0194 
447.3298 
443.9289 
442.0836 
438.0062 
433.8566 
434.2498 
429.2427 
429.5514 
426.2294 
427.7186 
422.5981 
420.9618 
423.5213 
420.0013 
419.3755 
419.1343 
416.7918 
417.4120 
416.1927 
415.7948 
414.2808 
417.2159 
412.8028 
412.9430 
412.2204 
411.2229 
410.8450 
409.8816 
413.2582 
410.7975 
409.4642 
412.0047 
407.1930 
406.0265 
406.5639 
406.7892 
405.6595 
404.1230 
406.5472 
405.5169 
402.9649 
405.4214 
403.9426 
404.1941 
398.5530 
401.5262 
401.3565 
402.1957 
403.8506 
403.3122 
398.2057 
400.4438 
398.3638 
400.0352 
402.7939 
401.0776 
398.4706 
395.7899 
397.6516 
397.7653 
398.8063 
395.6877 
398.3478 
400.2713 
400.6143 
396.0247
399.0337 
397.5524 
398.9661 
401.0980];

Val_Loss_Sym4_4_CNN = [3814.5728
2723.2383
2089.1113
1668.0911
1478.2522
1472.0686
1447.8641
1452.4230
1451.0198
1450.8422
1451.2748
1447.3909
1452.7256
1439.3141
1432.0497
1454.5845
1431.3160
1432.7532
1438.5109
1421.9114
1419.9683
1436.479
1427.6426
1431.1953
1449.6617
1406.8636
1425.3103
1444.9860
1417.6804
1420.9772
1442.3665
1425.9120
1416.3986
1429.1583
1395.6172
1413.0737
1426.8226
1422.9957
1426.0361
1433.4479
1421.1666
1420.8176
1397.5212
1392.6572
1406.2480
1406.5437
1400.3685
1399.6713
1412.9843
1406.7991
1404.9972
1404.5699
1400.6681
1401.0750
1416.0037
1412.9564
1401.8557
1409.5919
1404.3909
1410.8623
1398.2863
1385.9772
1407.5488
1403.0211
1422.2285
1402.9072
1408.2499
1387.4491
1401.1858
1400.1973
1415.9379
1412.5540
1399.1691
1403.9380
1393.4188
1396.3829
1393.1787
1390.8475
1411.1173
1415.1498
1401.6409
1410.3091];

LW = 2.5;
FS = 12;
%% Plot
Early_Stopping_patience = 20;
ES = length(Val_Loss_Sym4_4_CNN)-Early_Stopping_patience;
figure,
plot(Train_Loss_Sym4_4_CNN,'LineWidth',LW)
hold on
plot(Val_Loss_Sym4_4_CNN,'LineWidth',LW)
plot(ES,Val_Loss_Sym4_4_CNN(ES),'LineWidth',LW,...
    'Marker','*','Color','k')
plot(ES,Train_Loss_Sym4_4_CNN(ES),'LineWidth',LW,...
    'Marker','*','Color','k')
legend('Training Loss ',...
    'Validation Loss ',...
    'Early Stopping Point','FontSize',FS)
ylabel('Sym4-CNN Loss Functions @ M=4', 'FontSize',FS)
xlabel('Epoch', 'FontSize',FS)
grid on
%%  
Train_Loss_WHT_CNN_8 = [1309.52734375,
 830.9605712890625,
 579.1814575195312,
 423.8537902832031,
 350.7164001464844,
 327.05322265625,
 319.4491271972656,
 314.61981201171875,
 312.955810546875,
 309.7095642089844,
 305.5790710449219,
 301.0866394042969,
 294.28125,
 288.1459045410156,
 281.0950622558594,
 278.1698913574219,
 274.8823547363281,
 272.3773193359375,
 270.45672607421875,
 269.3555908203125,
 268.0813903808594,
 266.49884033203125,
 265.08984375,
 263.4843444824219,
 262.90948486328125,
 262.4479675292969,
 261.1565856933594,
 260.33551025390625,
 258.9122314453125,
 258.3760681152344,
 257.2071533203125,
 256.0191650390625,
 255.3778533935547,
 254.95547485351562,
 254.4484100341797,
 253.44070434570312,
 253.49073791503906,
 252.12867736816406,
 251.5322265625,
 251.19566345214844,
 251.03257751464844,
 249.78053283691406,
 249.69659423828125,
 248.95355224609375,
 248.50637817382812,
 248.01951599121094,
 247.2662811279297,
 247.0360107421875,
 246.869384765625,
 246.29994201660156,
 245.9581298828125,
 245.216552734375,
 244.6570281982422,
 244.36642456054688,
 244.200439453125,
 243.83096313476562,
 243.26597595214844,
 243.0773162841797,
 242.7194366455078,
 242.3088836669922,
 241.67051696777344,
 241.7555694580078,
 241.39877319335938,
 240.79774475097656,
 240.81072998046875,
 240.2163543701172,
 239.7774200439453,
 239.62867736816406,
 238.97125244140625,
 239.09054565429688,
 238.6767578125,
 238.29690551757812,
 237.78643798828125,
 237.67442321777344,
 237.88636779785156,
 237.2986297607422,
 237.1162872314453,
 236.5902557373047,
 236.38084411621094,
 236.18572998046875,
 236.15170288085938,
 235.6279296875,
 235.43748474121094,
 235.42027282714844,
 235.0642547607422];


Val_Loss_WHT_CNN_8 = [3279.401123046875,
 2402.930419921875,
 1710.420654296875,
 1262.765380859375,
 1167.1966552734375,
 1115.264404296875,
 1103.2178955078125,
 1098.10302734375,
 1081.8836669921875,
 1100.7579345703125,
 1129.2396240234375,
 1092.0899658203125,
 1088.2193603515625,
 1075.32080078125,
 1087.8916015625,
 1065.741943359375,
 1087.686767578125,
 1074.9405517578125,
 1068.765869140625,
 1076.0621337890625,
 1070.4736328125,
 1102.4443359375,
 1057.839599609375,
 1114.1954345703125,
 1066.2564697265625,
 1081.79736328125,
 1071.187744140625,
 1061.1568603515625,
 1080.3531494140625,
 1094.7896728515625,
 1059.921630859375,
 1077.5714111328125,
 1061.866943359375,
 1076.482666015625,
 1071.4268798828125,
 1097.14697265625,
 1071.1337890625,
 1061.4317626953125,
 1088.8289794921875,
 1039.96044921875,
 1056.2412109375,
 1079.4510498046875,
 1094.2169189453125,
 1086.8883056640625,
 1036.110595703125,
 1048.8831787109375,
 1057.724365234375,
 1053.2974853515625,
 1033.7802734375,
 1099.7066650390625,
 1035.3448486328125,
 1115.8314208984375,
 1034.2882080078125,
 1059.0716552734375,
 1047.4896240234375,
 1070.1240234375,
 1052.7208251953125,
 1027.980712890625,
 1052.554443359375,
 1119.7698974609375,
 1023.9037475585938,
 1035.689208984375,
 1051.64013671875,
 1075.7147216796875,
 1019.4783325195312,
 1031.9312744140625,
 1032.1727294921875,
 1077.0601806640625,
 1047.64208984375,
 1083.69580078125,
 1058.7335205078125,
 1053.3670654296875,
 1020.2085571289062,
 1019.7383422851562,
 1053.5927734375,
 1061.563720703125,
 1044.89697265625,
 1066.92431640625,
 1022.8530883789062,
 1029.665771484375,
 1040.65869140625,
 1027.47705078125,
 1052.56884765625,
 1045.9708251953125,
 1040.3546142578125];

%% plot
Early_Stopping_patience = 20;
ES = length(Val_Loss_WHT_CNN_8)-Early_Stopping_patience;
figure,
plot(Train_Loss_WHT_CNN_8,'LineWidth',LW)
hold on
plot(Val_Loss_WHT_CNN_8,'LineWidth',LW)
plot(ES,Val_Loss_WHT_CNN_8(ES),'LineWidth',LW,...
    'Marker','*','Color','k')
plot(ES,Train_Loss_WHT_CNN_8(ES),'LineWidth',LW,...
    'Marker','*','Color','k')
legend('Training Loss ',...
    'Validation Loss ',...
    'Early Stopping Point','FontSize',FS)
ylabel('WHT-CNN Loss Functions @ M=8', 'FontSize',FS)
xlabel('Epoch', 'FontSize',FS)
grid on

%% SGD vs. RMSprop